![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![GitHub repo size](https://img.shields.io/github/repo-size/priyasilent/zero-shot-detection-clip-attributes)
![GitHub last commit](https://img.shields.io/github/last-commit/priyasilent/zero-shot-detection-clip-attributes)

# Attribute-aware Zero-Shot Detection (CLIP)
This repository contains code and experiments for attribute-aware zero-shot object detection using CLIP embeddings and knowledge-driven attribute prompts.

## Datasets
Datasets are not included in this repository.
Download/attach from Kaggle:
- COCO128: https://www.kaggle.com/datasets/ultralytics/coco128
- Flickr Image Dataset: https://www.kaggle.com/datasets/hsankesara/flickr-image-dataset
- Visual Genome: https://www.kaggle.com/datasets/mathurinache/visual-genome

## How to run (Recommended)
1. Open Kaggle Notebooks
2. Upload this notebook
3. Attach the datasets above via Kaggle “Add data”
4. Run all cells

This work implements attribute-aware zero-shot object detection using CLIP. The model leverages language-driven attribute prompts to detect unseen object classes without additional training.

## Notes
This repository accompanies a master’s thesis on attribute-aware zero-shot object detection.
It is provided for transparency and reproducibility of the experimental pipeline.



